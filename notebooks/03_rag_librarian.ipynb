{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bded81d",
   "metadata": {},
   "source": [
    "### 1. Environment Setup & Advanced RAG Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ac7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, yaml, json\n",
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "import weaviate.classes.config as wvc\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables for Weaviate Cloud (WCD) and Hugging Face\n",
    "load_dotenv()\n",
    "\n",
    "# Load centralized project configuration\n",
    "with open(\"../src/config/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"‚úÖ Environment initialized for Advanced RAG.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8ed778",
   "metadata": {},
   "source": [
    "### 2. Weaviate Cloud Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate_url = os.getenv(\"WEAVIATE_URL\")\n",
    "weaviate_key = os.getenv(\"WEAVIATE_API_KEY\")\n",
    "hf_key = os.getenv(\"HF_TOKEN\") # Used for server-side vectorization\n",
    "\n",
    "# Connect to Weaviate Cloud\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=weaviate_url,\n",
    "    auth_credentials=Auth.api_key(weaviate_key),\n",
    "    headers={\"X-HuggingFace-Api-Key\": hf_key}\n",
    ")\n",
    "\n",
    "if client.is_ready():\n",
    "    print(f\"‚úÖ Librarian connected to Weaviate Cloud at: {weaviate_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bdcedc",
   "metadata": {},
   "source": [
    "### 3. Collection Schema & Indexing Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1842b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = config['weaviate']['class_name']\n",
    "\n",
    "# Reset collection for a clean indexing run\n",
    "if client.collections.exists(class_name):\n",
    "    client.collections.delete(class_name)\n",
    "    print(f\"üóëÔ∏è Cleaned existing collection: {class_name}\")\n",
    "\n",
    "# Create Collection with Hybrid-Search Readiness\n",
    "client.collections.create(\n",
    "    name=class_name,\n",
    "    # Configure Server-Side Vectorization\n",
    "    vectorizer_config=wvc.Configure.Vectorizer.text2vec_huggingface(\n",
    "        model=config['weaviate']['vectorizer_model'],\n",
    "        wait_for_model=True\n",
    "    ),\n",
    "    properties=[\n",
    "        wvc.Property(name=\"content\", data_type=wvc.DataType.TEXT),\n",
    "        wvc.Property(name=\"chunk_index\", data_type=wvc.DataType.INT),\n",
    "        wvc.Property(name=\"source\", data_type=wvc.DataType.TEXT)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Collection '{class_name}' configured for Hybrid Search.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295c0d43",
   "metadata": {},
   "source": [
    "### 4. Data Ingestion & Batch Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb35fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = config['paths']['train_data']\n",
    "\n",
    "print(f\"üìÇ Loading chunks from: {data_path}\")\n",
    "\n",
    "with open(data_path, \"r\") as f:\n",
    "    training_data = [json.loads(line) for line in f]\n",
    "\n",
    "collection = client.collections.get(class_name)\n",
    "\n",
    "# Perform Dynamic Batch Upload\n",
    "with collection.batch.dynamic() as batch:\n",
    "    for idx, item in enumerate(training_data):\n",
    "        batch.add_object(\n",
    "            properties={\n",
    "                \"content\": item[\"input\"],\n",
    "                \"chunk_index\": idx,\n",
    "                \"source\": \"Uber-2024-Annual-Report\"\n",
    "            }\n",
    "        )\n",
    "            \n",
    "print(f\"‚úÖ Indexed {len(training_data)} financial chunks into Non-Parametric Memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca638802",
   "metadata": {},
   "source": [
    "### 5. Advanced Hybrid RAG Pipeline (The Librarian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e832448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Load Cross-Encoder Reranker Model\n",
    "reranker = CrossEncoder(config['weaviate']['reranker_model'])\n",
    "\n",
    "def reciprocal_rank_fusion(ranked_lists: List[List[Tuple[str, any]]], k: int = 60) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Implements Reciprocal Rank Fusion (RRF) algorithm.\n",
    "    \n",
    "    RRF Score Formula: RRF(d) = Œ£ 1/(k + rank_i(d))\n",
    "    where:\n",
    "        - d is a document\n",
    "        - rank_i(d) is the rank of document d in retrieval system i\n",
    "        - k is a constant (typically 60) to prevent division issues\n",
    "    \n",
    "    Args:\n",
    "        ranked_lists: List of ranked result lists from different retrievers\n",
    "                     Each list contains tuples of (doc_id, document_object)\n",
    "        k: RRF constant parameter (default: 60)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary mapping doc_id to RRF score\n",
    "    \"\"\"\n",
    "    rrf_scores = {}\n",
    "    \n",
    "    # Process each retrieval system's results\n",
    "    for ranked_list in ranked_lists:\n",
    "        for rank, (doc_id, doc_obj) in enumerate(ranked_list):\n",
    "            # Initialize score if this is first time seeing this document\n",
    "            if doc_id not in rrf_scores:\n",
    "                rrf_scores[doc_id] = {'score': 0.0, 'doc': doc_obj}\n",
    "            \n",
    "            # Add RRF contribution from this retriever\n",
    "            # rank starts at 0, so we add 1 to get position\n",
    "            rrf_scores[doc_id]['score'] += 1.0 / (k + rank + 1)\n",
    "    \n",
    "    return rrf_scores\n",
    "\n",
    "def query_librarian(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Advanced RAG Workflow with Explicit RRF Implementation:\n",
    "    \n",
    "    Step 1: Dense Vector Search (Semantic Retrieval)\n",
    "    Step 2: BM25 Keyword Search (Lexical Retrieval)  \n",
    "    Step 3: Reciprocal Rank Fusion (Combine Rankings)\n",
    "    Step 4: Cross-Encoder Reranking (Precision Optimization)\n",
    "    \n",
    "    Args:\n",
    "        question: User query\n",
    "    \n",
    "    Returns:\n",
    "        Best matching content from the annual report\n",
    "    \"\"\"\n",
    "    collection = client.collections.get(config['weaviate']['class_name'])\n",
    "    \n",
    "    # Load retrieval parameters from config\n",
    "    retrieval_config = config['weaviate'].get('retrieval', {})\n",
    "    dense_top_k = retrieval_config.get('dense_top_k', 20)\n",
    "    bm25_top_k = retrieval_config.get('bm25_top_k', 20)\n",
    "    rrf_k = retrieval_config.get('rrf_k', 60)\n",
    "    final_top_k = retrieval_config.get('final_top_k', 10)\n",
    "    \n",
    "    # Step 1: Dense Vector Search \n",
    "    # Semantic similarity using embeddings - captures meaning\n",
    "    vector_results = collection.query.near_text(\n",
    "        query=question,\n",
    "        limit=dense_top_k\n",
    "    )\n",
    "    \n",
    "    # Step 2: BM25 Keyword Search \n",
    "    # Lexical matching - critical for exact financial entities like \"$1.97 billion\"\n",
    "    bm25_results = collection.query.bm25(\n",
    "        query=question,\n",
    "        limit=bm25_top_k\n",
    "    )\n",
    "    \n",
    "    # Check if we got any results\n",
    "    if not vector_results.objects and not bm25_results.objects:\n",
    "        return \"No relevant information found in the annual report.\"\n",
    "    \n",
    "    # Step 3: Reciprocal Rank Fusion (RRF)\n",
    "    # Prepare ranked lists with document IDs for RRF\n",
    "    vector_ranked = [(str(obj.uuid), obj) for obj in vector_results.objects]\n",
    "    bm25_ranked = [(str(obj.uuid), obj) for obj in bm25_results.objects]\n",
    "    \n",
    "    # Apply RRF algorithm to combine rankings\n",
    "    rrf_scores = reciprocal_rank_fusion(\n",
    "        ranked_lists=[vector_ranked, bm25_ranked],\n",
    "        k=rrf_k\n",
    "    )\n",
    "    \n",
    "    # Sort by RRF score and take top candidates\n",
    "    rrf_sorted = sorted(\n",
    "        rrf_scores.items(), \n",
    "        key=lambda x: x[1]['score'], \n",
    "        reverse=True\n",
    "    )[:final_top_k]\n",
    "    \n",
    "    # Extract documents for reranking\n",
    "    rrf_candidates = [doc_data['doc'] for doc_id, doc_data in rrf_sorted]\n",
    "    \n",
    "    if not rrf_candidates:\n",
    "        return \"No relevant information found after RRF fusion.\"\n",
    "    \n",
    "    # Step 4: Cross-Encoder Reranking \n",
    "    # Final precision step: compute contextualized relevance scores\n",
    "    candidate_texts = [obj.properties[\"content\"] for obj in rrf_candidates]\n",
    "    \n",
    "    # Create query-document pairs for cross-encoder\n",
    "    pairs = [[question, text] for text in candidate_texts]\n",
    "    \n",
    "    # Calculate relevance scores using cross-attention\n",
    "    rerank_scores = reranker.predict(pairs)\n",
    "    \n",
    "    # Find the highest-scoring passage\n",
    "    best_idx = rerank_scores.argmax()\n",
    "    \n",
    "    # Return the most relevant content\n",
    "    return candidate_texts[best_idx]\n",
    "\n",
    "# ========== Test Run ==========\n",
    "test_q = \"What are the primary risks associated with the new debt instruments?\"\n",
    "print(f\"‚ùì Query: {test_q}\")\n",
    "print(f\"\\nüîç Running Advanced RAG Pipeline:\")\n",
    "print(f\"   Method: {config['weaviate'].get('retrieval', {}).get('method', 'explicit_rrf')}\")\n",
    "print(f\"   Step 1: Dense Vector Search (top_k={config['weaviate'].get('retrieval', {}).get('dense_top_k', 20)})\")\n",
    "print(f\"   Step 2: BM25 Keyword Search (top_k={config['weaviate'].get('retrieval', {}).get('bm25_top_k', 20)})\")\n",
    "print(f\"   Step 3: Reciprocal Rank Fusion (k={config['weaviate'].get('retrieval', {}).get('rrf_k', 60)})\")\n",
    "print(f\"   Step 4: Cross-Encoder Reranking (final={config['weaviate'].get('retrieval', {}).get('final_top_k', 10)})\")\n",
    "\n",
    "result = query_librarian(test_q)\n",
    "print(f\"\\nüìö Librarian Citation (Top Result after RRF + Reranking):\\n{result[:400]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
